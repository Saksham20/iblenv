{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONE Introductory Tutorial\n",
    "In this tutorial we will use ONE to load IBL behavioural data and perform some simple analysis to assess the performance of a chosen subject during the [IBL task](https://www.biorxiv.org/content/10.1101/2020.01.17.909838v2.full).\n",
    "\n",
    "This tutorial assumes that you have setup the [unified ibl environment](../../02_installation.md) and authorised access to IBL data through your [ONE credentials](../../one_docs/one_credentials.md). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get started by importing the ONE module and setting up a connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to https://alyx.internationalbrainlab.org as mayo"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from oneibl.one import ONE\n",
    "one = ONE()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to look at behavioural data for a subject in a given lab. We can see which labs are available by using,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['angelakilab',\n",
       " 'hoferlab',\n",
       " 'steinmetzlab',\n",
       " 'mainenlab',\n",
       " 'danlab',\n",
       " 'cortexlab',\n",
       " 'mrsicflogellab',\n",
       " 'churchlandlab',\n",
       " 'zadorlab',\n",
       " 'wittenlab']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one.list(None, 'labs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will choose a subject from the cortex lab. To find which subjects are available we will use the `one.alyx.rest` command. See [here](../one_advanced/one_advanced.html) for more information about this command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_info = one.alyx.rest('subjects', 'list', lab='cortexlab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many subjects have been registered under the cortex lab and also examine the content of the first item in subj_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of subjects in cortex lab = 61"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'nickname': 'ALK081',\n",
       " 'url': 'https://alyx.internationalbrainlab.org/subjects/ALK081',\n",
       " 'id': 'c68cf5d5-e75a-46f1-8eda-a2db78cf4743',\n",
       " 'responsible_user': 'armin',\n",
       " 'birth_date': '2018-04-13',\n",
       " 'age_weeks': 33,\n",
       " 'death_date': '2018-12-04',\n",
       " 'species': None,\n",
       " 'sex': 'F',\n",
       " 'litter': 'Pv_L_019',\n",
       " 'strain': 'C57BL/6J',\n",
       " 'source': None,\n",
       " 'line': 'Pvalb-IRES-Cre',\n",
       " 'projects': ['ibl_behaviour_pilot_matlabrig'],\n",
       " 'session_projects': ['ibl_behaviour_pilot_matlabrig'],\n",
       " 'lab': 'cortexlab',\n",
       " 'genotype': ['Pv-Cre +/-'],\n",
       " 'description': 'perfused by HF',\n",
       " 'alive': False,\n",
       " 'reference_weight': 25.0,\n",
       " 'last_water_restriction': None,\n",
       " 'expected_water': 0.9520000000000001,\n",
       " 'remaining_water': 0.9520000000000001}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"No. of subjects in cortex lab = {len(subj_info)}\")\n",
    "subj_info[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each entry in the list subj_info is a dictionary that contains the details about this subject, including among others details, the nickname, whether the subject is alive or dead and the gender of the subject. We are interested in finding out the possible subject nicknames so we can refine our search. We can quickly iterate over all items in the subj_info list and extract the subject nicknames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ALK081', 'ALK082', 'C57_0077_Breeding', 'CR_IBL1', 'CR_IBL2', 'CSHL062', 'CtTa_0112_Breeding', 'dop_11', 'KS001', 'KS001_optoproject', 'KS002', 'KS003', 'KS004', 'KS005', 'KS006', 'KS007', 'KS008', 'KS009', 'KS010', 'KS011', 'KS012', 'KS013', 'KS014', 'KS015', 'KS016', 'KS017', 'KS018', 'KS019', 'KS020', 'KS021', 'KS022', 'KS023', 'KS024', 'KS025', 'KS026', 'KS027', 'KS028', 'KS030', 'KS031', 'KS032', 'KS033', 'KS034', 'KS035', 'KS036', 'KS037', 'KS038', 'KS039', 'KS040', 'KS041', 'LEW006', 'LEW008', 'LEW009', 'LEW010', 'M181212_IC1', 'Muller', 'MW001', 'MW002', 'MW003', 'MW004', 'Pv_0079_Breeding', 'TetO_0055_Breeding']"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "subject_names = [subj['nickname'] for subj in subj_info]\n",
    "print(subject_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's choose subject KS022 for further analysis and find all the sessions for this subject using the `one.search` command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eids, sess_info = one.search(subject='KS022', task_protocol='training', details=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Note\n",
    "\n",
    "We have restricted the task_protocol to find sessions that only have trainig data. We could also have restricted this field by `biased` or `ephys` to find sessions where the subject was in a more advanced stage of the [IBL training pipeline](https://figshare.com/articles/A_standardized_and_reproducible_method_to_measure_decision-making_in_mice_Appendix_2_IBL_protocol_for_mice_training/11634729/1)\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By returning the session information for each eID we can extract the date and order our experimental sessions by date (or training days). Let's first look at the content of the first element in `sess_info`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subject': 'KS022',\n",
       " 'start_time': '2019-10-22T11:48:05.403000',\n",
       " 'number': 2,\n",
       " 'lab': 'cortexlab',\n",
       " 'project': 'ibl_neuropixel_brainwide_01',\n",
       " 'url': 'https://alyx.internationalbrainlab.org/sessions/b4ac5904-5693-4d98-adb3-362e612836be',\n",
       " 'task_protocol': '_iblrig_tasks_trainingChoiceWorld6.0.5',\n",
       " 'local_path': 'cortexlab\\\\Subjects\\\\KS022\\\\2019-10-22\\\\002'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess_info[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see this contains information about the date of the session and so we can quickly collect a list dates for all the training sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_date = [sess['start_time'] for sess in sess_info]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The latest training session date is returned first. For convenienve let's reverse the list so that the first training session day is at index 0, for consistency we must reverse the list of eids as well "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_date.reverse()\n",
    "eids.reverse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by looking at data for the first training day. Let's list what datasets are available using `one.list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_ibl_trials.stimOnTrigger_times',\n",
       " '_iblrig_Camera.raw',\n",
       " '_iblrig_Camera.timestamps',\n",
       " '_iblrig_VideoCodeFiles.raw',\n",
       " '_iblrig_ambientSensorData.raw',\n",
       " '_iblrig_codeFiles.raw',\n",
       " '_iblrig_encoderEvents.raw',\n",
       " '_iblrig_encoderPositions.raw',\n",
       " '_iblrig_encoderTrialInfo.raw',\n",
       " '_iblrig_taskData.raw',\n",
       " '_iblrig_taskSettings.raw',\n",
       " 'trials.choice',\n",
       " 'trials.contrastLeft',\n",
       " 'trials.contrastRight',\n",
       " 'trials.feedbackType',\n",
       " 'trials.feedback_times',\n",
       " 'trials.firstMovement_times',\n",
       " 'trials.goCueTrigger_times',\n",
       " 'trials.goCue_times',\n",
       " 'trials.included',\n",
       " 'trials.intervals',\n",
       " 'trials.probabilityLeft',\n",
       " 'trials.repNum',\n",
       " 'trials.response_times',\n",
       " 'trials.rewardVolume',\n",
       " 'trials.stimOn_times',\n",
       " 'wheel.position',\n",
       " 'wheel.timestamps',\n",
       " 'wheelMoves.intervals',\n",
       " 'wheelMoves.peakAmplitude']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eid_day1 = eids[0]\n",
    "one.list(eid=eid_day1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we are interested in the in the [trials dataset](https://docs.google.com/spreadsheets/d/1ieLXRPLLSgUKcLvFkrqizfZl5HjdfE6bQ2KLBCRmjQo/edit#gid=1097679410) that contains information about the performance of the subject during the task. We can define a list of all the individual data set types we want to load, for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_types = ['trials.choice',\n",
    "           'trials.contrastLeft']\n",
    "_ = one.load(eid=eid_day1, dataset_types=d_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively we can take advantage of the ALF file format and download all files that have the prefix trials. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Note\n",
    "\n",
    "This would be called loading all attributes associated with the trials object. See [here](../../04_reference#ALF) for more information on the ALF file naming convention that is used in the IBL.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this we will use a slightly different loading function `one.load_object`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_object = 'trials'\n",
    "_ = one.load_object(eid=eid_day1, obj=d_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find the path where the data has been downloaded using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('cortexlab/Subjects/KS022/2019-09-23/001')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = one.path_from_eid(eid_day1)\n",
    "data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The alf module in ibllib contains a useful set of functions that can be used to read in alf objects. Let's import this module and load in all data associated with the trials object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid ALF filename",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-a8a9a599c1ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0malf_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'alf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtrials_day1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malf_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'trials'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\iblenv\\ibllib-repo\\alf\\io.py\u001b[0m in \u001b[0;36mload_object\u001b[1;34m(alfpath, object, short_keys, **kwargs)\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malfpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mobject\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'If a directory is provided, the object name should be provided too'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m     \u001b[0mfiles_alf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malfpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m     \u001b[1;31m# Take attribute and timescale from parts list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m     \u001b[0mattributes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'_'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\iblenv\\ibllib-repo\\alf\\io.py\u001b[0m in \u001b[0;36m_ls\u001b[1;34m(alfpath, object, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m             \u001b[0mfiles_alf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattributes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter_by\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malfpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m         \u001b[0mobject\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malf_parts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malfpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m         \u001b[0malfpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malfpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[0mfiles_alf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattributes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter_by\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malfpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\iblenv\\ibllib-repo\\alf\\files.py\u001b[0m in \u001b[0;36malf_parts\u001b[1;34m(filename, as_dict)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mALF_EXP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Invalid ALF filename'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mas_dict\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid ALF filename"
     ]
    }
   ],
   "source": [
    "import alf.io as aio\n",
    "from pathlib import Path\n",
    "\n",
    "alf_path = Path(data_path, 'alf')\n",
    "\n",
    "trials_day1 = aio.load_object(alf_path, 'trials')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Note\n",
    "\n",
    "By using `trials_day1 = one.load(eid=eid, data_types=dtypes)` we could have automatically loaded the trials object into memory after downloading the files. Here we have chosen to manually read in the data to introduce the useful functions such `one.path_from_eid` and `alf.io.load_object`\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the content of the trials object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trials_day1.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find how many trials there were in the session by inspecting the length of one of the attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials_day1 = len(trials_day1.choice)\n",
    "print(n_trials_day1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Note\n",
    "\n",
    "We chose to look at the first attribute of trials oject to find the no. of trials, but we could have looked at the length of any of the attributes and got the same results. This is another consequence of the ALF file format. All attributes associated with a given object will have the same number of rows.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's look at the visual stimulus contrasts that were presented to the subject on day 1. For this we will inspect `trials.constrastLeft` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_day1.contrastLeft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have three values 1 which indicates a 100 % visual stimulus contrast, 0.5 which corresponds to a 50 % visual contrast and whole load of nans....."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we inspect `trials.contrastRight` we will find that all the indices that contain nans in the `trials.contrastLeft` are filled in `trials.contrastRight`, and vice versa. nans in the `trials.contrastLeft` and `trials.contrastRight` datasets indicate that the contrast was show on the oppisite side."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets combine `trials.contrastLeft` and `trials.contrastRight` into a new dataset called `trials.contrast`. By convetion in the IBL, contrasts that appear on the left are assigned a negative while those on the right are positive. Let's also reflect this convention when forming our new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "trials_day1.contrast = np.empty((n_trials_day1))\n",
    "contrastRight_idx = np.where(~np.isnan(trials_day1.contrastRight))[0]\n",
    "contrastLeft_idx = np.where(~np.isnan(trials_day1.contrastLeft))[0]\n",
    "\n",
    "trials_day1.contrast[contrastRight_idx] = trials_day1.contrastRight[contrastRight_idx]\n",
    "trials_day1.contrast[contrastLeft_idx] = -1 * trials_day1.contrastLeft[contrastLeft_idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect how many of each type of contrast was presented to the subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrasts, n_contrasts = np.unique(trials_day1.contrast, return_counts=True)\n",
    "print(f\"Visual stimulus contrasts on day 1 = {contrasts * 100}\")\n",
    "print(f\"No. of each contrast on day 1 = {n_contrasts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's look at how the mouse performed on the first day of training. This information is stored in the `feedbackType` attribute of the `trials` object. A positive feedback (+1) means the mouse got the task correct, whereas a negavtive feedback (-1) means the mouse got the trial wrong. Let's double check that these are the only values we see in `trials.feedbakType`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(trials_day1.feedbackType)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily compute the performance of the mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = np.sum(trials_day1.feedbackType == 1) / n_trials_day1\n",
    "print(f\"Correct = {correct * 100} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected on the first day of training the mouse has not yet grasped the concept of the task and performed at chance level. We can break down the performance at each contrast level and create a simple plot. In this plot let's also express performance in terms of rightward choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "contrast_performance = np.empty((contrasts.size))\n",
    "for ic, c in enumerate(contrasts):\n",
    "    contrast_idx = np.where(trials_day1.contrast == c)[0]\n",
    "    if c < 0:\n",
    "        contrast_performance[ic] = 1 - (np.sum(trials_day1.feedbackType\n",
    "                                               [contrast_idx] == 1) / contrast_idx.shape[0])\n",
    "    else:\n",
    "        contrast_performance[ic] = (np.sum(trials_day1.feedbackType\n",
    "                                           [contrast_idx] == 1) / contrast_idx.shape[0])\n",
    "\n",
    "plt.plot(contrasts * 100, contrast_performance * 100, 'o-', lw=3, ms=10)\n",
    "plt.ylim([0, 100])\n",
    "plt.xticks([*(contrasts * 100)])\n",
    "plt.xlabel('Signed contrast (%)')\n",
    "plt.ylabel('Rightward choice (%)')\n",
    "\n",
    "print(contrast_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the mice learns the task we expect its performance to improve. Let's repeat the steps above and see how the same mouse performed on day 15 of trainng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eid_day15 = eids[14]\n",
    "trials_day15 = one.load_object(eid=eid_day15, obj=d_object)\n",
    "n_trials_day15 = len(trials_day15.choice)\n",
    "\n",
    "trials_day15.contrast = np.empty((n_trials_day15))\n",
    "contrastRight_idx = np.where(~np.isnan(trials_day15.contrastRight))[0]\n",
    "contrastLeft_idx = np.where(~np.isnan(trials_day15.contrastLeft))[0]\n",
    "\n",
    "trials_day15.contrast[contrastRight_idx] = trials_day15.contrastRight[contrastRight_idx]\n",
    "trials_day15.contrast[contrastLeft_idx] = -1 * trials_day15.contrastLeft[contrastLeft_idx]\n",
    "\n",
    "contrasts, n_contrasts = np.unique(trials_day15.contrast, return_counts=True)\n",
    "print(f\"Visual stimulus contrasts on day 15 = {contrasts * 100}\")\n",
    "print(f\"No. of each contrast on day 15 = {n_contrasts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how on day 15 the mouse has not only has trials with 100 % and 50 % visual stimuli contrast but also 25 % and 12.5 %. This follows the IBL training protocol where harder contrasts are introduced as the mouse becomes more expert at the task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = np.sum(trials_day15.feedbackType == 1) / n_trials_day15\n",
    "print(f\"Correct = {correct * 100} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance has vastly improved compared to day 1 of training! Once again let's break this down further into the performance at each contrast and creata a plot of rightward choice vs signed contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_performance = np.empty((contrasts.size))\n",
    "for ic, c in enumerate(contrasts):\n",
    "    contrast_idx = np.where(trials_day15.contrast == c)[0]\n",
    "    if c < 0:\n",
    "        contrast_performance[ic] = 1 - (np.sum(trials_day15.feedbackType\n",
    "                                               [contrast_idx] == 1) / contrast_idx.shape[0])\n",
    "    else:\n",
    "        contrast_performance[ic] = (np.sum(trials_day15.feedbackType\n",
    "                                           [contrast_idx] == 1) / contrast_idx.shape[0])\n",
    "\n",
    "plt.plot(contrasts * 100, contrast_performance * 100, 'o-', lw=3, ms=10)\n",
    "plt.ylim([0, 100])\n",
    "plt.xticks([*(contrasts * 100)])\n",
    "plt.xlabel('Signed contrast (%)')\n",
    "plt.ylabel('Rightward choice (%)')\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "print(contrast_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now be familiar with the basics of how to search for and load data using ONE and how to do some simple analysis with data from the IBL task. To see how to replicate this tutorial using Datajoint, please see this [tutorial](../dj_intro/dj_intro.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
